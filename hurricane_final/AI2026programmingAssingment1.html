
<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>AI Assignment 1</title>

</head>

<body>
	<center>
	<h1>Introduction to Artificial Intelligence </h1>
	<h3>Assignment 1</h3>
	</center>
<hr>
	<h2>Environment simulator and agents for the Hurricane Evacuation Problem</h2>
<p>
In this first exercise you are asked to implement an environment
simulator that runs a path optimization problem.
Then, you will implement some agents that live in the environment
and evaluate their performance.

</p><p>
We are given a weighted graph G=(V,E,w) and a set of target vertices S,
and the goal is (starting at a given vertex) to visit all the target vertices,
as quickly as possible. Edges have designations, and there are items that can be picked up in graph vertices (see below),
Unlike standard shortest path problems in graphs,
which have easy known efficient solution methods (e.g. the Dijkstra algorithm), here the
problem is that there is more than 1 vertex to visit, and their order
is not given.
This is a problem encountered in many real-world settings, such as when
you are trying to evacuate people who are stuck at home with no transportation before
the hurricane arrives.

</p><h3>Hurricane Evacuation problem environment</h3>

<p>
The environment consists of a weighted undirected graph, with weights being positive integers. Each vertex may contain
a number of people to be evacuated. Edges signify roads, and a road may either be OK or FLOODED. 
A flooded road cannot be traversed unless the agent has equipped his vehicle with an AMPHIBIAN KIT (looks a bit like Boston's "duck tours" vehicle).
Amphibian kits start out at some vertices in the initial state. An agent at a vertex can EQUIP the kit, which takes time Q,
after which the agent can use flooded roads, but with speed a factor of integer  P>1 less than its usual speed, on both flodded and unflooded roads.
An agent can UNEQUIP the kit, which takes time U, and then goes back to traveling at normal speed, and the kit ramains in the
vertex at which this action was done.
An agent (evacuation vehicle) at a vertex automatically picks up all the people at this vertex just before starting the
next move, thereby saving them.
In this assignment
we assume complete knowledge of location of people to save, of flooded roads, and of amphibian kits.

</p><p>
An agent can only do  <b>traverse</b>, <b>equip</b>, <b>unequip</b>, and <b>no-op</b> actions.
The time for traverse  actions is equal to w, the edge weight (assumed to be a positive integer),
unless an amphibian kit is equipped, in which case the traversal time is w times P. 
The action always succeeds if the edge is unflooded or an amphibian kit is equipped (or both), otherwise is the same as <b>no-op</b> which takes one time unit.
The simulation ends when all people have been picked up, or there is no path for any agent to pick up any more people.
</p><p>
The simulator should keep track of time, the number of
actions done by each agent, and the total number of people successfully evacuated.

</p><h3>Implementation part I: simulator + simple agents</h3>
 
<p>
Initially you will implement the environment simulator, and several simple
(non-AI) agents. The environment simulator should start up by reading
the graph from a file, as well as the contents of vertices and global constants,
in a format of your choice. We suggest
using a simple adjancency list in an ASCII file, that initially specifies
the number of vertices. For example (comments beginning
with a semicolon):

</p><pre>
#N 4      ; number of vertices in graph (from 1 to N)
#U 1      ; takes 1 time unit to unequip
#Q 2      ; takes 2 time units to equip
#P 3      ; moving with amphibian kit is 3 times slower

#V1 K     ; Vertex 1, intially contains an amphibian kit
#V2 P1    ; Vertex 2, initially contains 1 person to be rescued
#V3 B     ; Vertex 3, nothing of interest
#V4 P2 K  ; Vertex 4, initially contains 2 persons to be rescued and an amphibian kit

#E1 1 2 W1 F               ; Edge 1 from vertex 1 to vertex 2, weight 1, flooded
#E2 3 4 W1                 ; Edge 2 from vertex 3 to vertex 4, weight 1
#E3 2 3 W1                 ; Edge 3 from vertex 2 to vertex 3, weight 1
#E4 1 3 W4                 ; Edge 4 from vertex 1 to vertex 3, weight 4
#E5 2 4 W5                 ; Edge 5 from vertex 2 to vertex 4, weight 5
</pre>

<p>
The simulator should query the user about the number of agents and
what agent program to use for each of them, from a list defined below.
Global constants and initialization parameters for each agent 
(initial position) are also to be queried from the user.

</p><p>
After the above initialization, the simulator should run each agent in turn,
performing the actions retured by the agents, and update the world
accordingly. Additionally, the simulator should be capable of displaying the
state of the world after each step, with the appropriate 
state of the agents and their score. The score of an agent is the number of people
saved by the agent times 1000, minus the time taken.
A simple screen display in ASCII is sufficient (no bonuses
for fancy graphics - this is not the point in this course!).

</p><p>
Each agent program (a function) works as follows. 
The agent is called by the simulator, together with
a set of observations. 
The agent returns a move to be carried out in the 
current world state. The agent is allowed to keep an internal state
(for example, a computed optimal path, or anything else desired) if needed.
In this assignment, the agents can observe the entire state of the world.

</p><p>
You should implement the following agents:

</p><ol>
<li> A <b>human</b> agent, i.e. print the state, read the next move from the user, and
return it to the simulator. This is used for debugging and evaluating the program.
</li><li> A <b> stupid greedy</b> agent, that works as follows: the agent should
compute the shortest currently unblocked path to the next vertex with people to be rescued,
and try to follow it.
If there is no such path, do <b>terminate</b>. Here and elsewhere, if needed, break ties by prefering lower-numbered
vertices and/or edges.
</li><li> A <b> thief</b>  agent, that steals amphibian kits and runs away. 
The thief works as follows: if it has not equipped an amphibian kit, it computes the shortest path to such a kit,
and moves in that direction. When it reaches a kit, it equips it. If equipped, it runs away: always tries to go as far  away from other agents as possible.
If not possible, it does a no-op. The thief does not pick up people.
Prefer the lowest-numbered vertices and edge in case of ties.
</li></ol>

<p>
At this stage, you should run the environment with <b>three</b> agents
participating in each run: one stupid greedy agent, one thief agent, and one
other agent that can be chosen by the user.
Your program should display and record the scores. In particular,
you should run the stupid greedy agent with various initial configurations.
Also, test your environment with several agents in the
same run, to see that it works correctly. You would be advised
to do a good job here w.r.t. program extensibility, modularity, etc.
much of this code may be used for some of the following
assignments as well. 

</p><p>
<b>Clarification and rationale:</b>
Note that this part of the assignment will not
really be checked, as it contains no AI, so details are not important.
The goal of this part of the assignment is constructing infrastructure 
for the rest of the assignment(s). E.g. the "human agent" is intended as
a debugging and demo aid, and also towards assignment 2, and the stupid greedy agent
contains code for shortest path that would be a component in a heuristic
in the 2nd part of this assignment.


</p><h3>Implementation part II: search agents</h3>

<p>
<b>Now</b>, after chapter 4, you will be implementing
intelligent agents (this is part 2 of the assignment)
that need to act in this environment. Each agent
should assume that it is acting alone, regardless of whether it is true.
You will be implementing a "search" agent as defined below.
All the algorithms will use an <b>admissible heuristic evaluation function</b> 
of your choice. The search algorithms you implement should 
just search for a path that minimizes the time to collect all people in the graph!

</p><ol>
<li> A greedy search agent (<b>not</b> the same as the stupid greedy agent above!),
 that picks the move with best immediate heuristic value to expand next.
</li><li> An agent using A* search, with the same heuristic. Assume a global constant of LIMIT
expansions (default 10000) beyond which we just return "fail", and the agent does just the "terminate"
action.
</li><li> An agent using the simplified version of real-time A* doing L (user determined constant,
L=10 by default) expansions before each move decision.
</li></ol>

<p>
The performance measure will be based on the "situated planning" idea of goal achievment time,
that is, recognizing that the search algorithm run also takes time!
Rather than using a real-time clock, we will simply have a per-expansion time
T, and if N expansions are run in the search
algorithm this means that N*T time has passed in real time.
The performance of an agent will thus be equal to S, when the path is actually executed in
"real time". For simplicity, we will start with T=0, that is,
assuming that search takes no time.

</p><p>
Note that if T is non-zero,
a path that looks optimal may actually
be bad because we have wasted a lot of time to find it,
when a simple quickly found path may be almost as good.
The number of expansions are: 1 per action for the greedy agent
(always 1 expansion),  and L per action for the "real-time A*", unless it has found the optimal path already in which case it now becomes 0 per move.
We will run all algorithms with values of T being 0, 0.000001, and 0.01
and report the performance results.

</p><p>
Observe that for "situated" A* this is a very hard problem for an algorithm that considers the deadline,
as we do not know the number of
expansions before we do the search! Many search applications just assume that the number of
expansions is maximal and equal to LIMIT, or ignore the effect on the goal achievement time,
but determining how to do this in a reasonable
manner is an open research problem. (Do this to earn an MSc, or even a PhD.)

</p><p>
<b>Bonus version</b>: construct a search agent as above, but in addition
allow one thief agent also acting in the environment.
Your search agent needs to take this into account.
Observe that although this seems to be a multi-agent problem,
the fact that the thief is perfectly predictable makes this in essence a single agent search problem.

</p><p>
<b>Addtional bonus - theoretical</b>: What is the computational complexity of the
Hurricane Evacuation Problem (single agent)? Can you prove that it is NP-hard? Or is it
in P? If the latter, can you design an algorithm that solves the problem in polynomial time?

</p><h2>Deliverables</h2>

<p>
The program and code sent to the grader, by e-mail or
otherwise as specified by the grader, a printout of the code and results.
A document stating the heuristic function you used and the rationale
for selecting this function.
Set up a time for frontal grading checking of the delivered assignment,
in which both members of each team must demonstrate at least <b>some</b>
familiarity with their program...

</p><p>

Due date for part 1 (recommended, not checked or enforced): November 15, 2025.
</p><p>
For the complete assignment: December 1, 2025.


</p></body></html>